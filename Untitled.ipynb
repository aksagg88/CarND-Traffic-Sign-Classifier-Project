{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (34799, 32, 32, 3)\n",
      "y_train shape: (34799,)\n",
      "X_valid shape: (4410, 32, 32, 3)\n",
      "y_valid shape: (4410,)\n",
      "X_test shape: (12630, 32, 32, 3)\n",
      "y_test shape: (12630,)\n"
     ]
    }
   ],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = './traffic-signs-data/train.p'\n",
    "validation_file= './traffic-signs-data/valid.p'\n",
    "testing_file = './traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target num of samples for each class: 4020\n",
      "Total num of training samples: 172860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def transform_image(img, ang_range=15,shear_range=8,trans_range=4):\n",
    "    '''Return an img with random rotation, translation and shear\n",
    "    \n",
    "    Modified from Yivek Yadav's approach using OpenCV (https://goo.gl/ttRKL0)\n",
    "    '''\n",
    "    img_warp = np.copy(img)\n",
    "    img_h, img_w, img_ch = img.shape\n",
    "    \n",
    "    # rotation\n",
    "    rot = np.random.uniform(ang_range)-ang_range/2  \n",
    "    rotM = cv2.getRotationMatrix2D((img_w/2,img_h/2),rot,1)\n",
    "\n",
    "    # translation\n",
    "    tr_x, tr_y = trans_range*np.random.uniform(size=(2,1))-trans_range/2\n",
    "    transM = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "\n",
    "    # shear\n",
    "    pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "    pt1  = 5+shear_range*np.random.uniform()-shear_range/2\n",
    "    pt2  = 20+shear_range*np.random.uniform()-shear_range/2\n",
    "    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "    shearM = cv2.getAffineTransform(pts1,pts2)\n",
    "        \n",
    "    img_warp = cv2.warpAffine(img_warp,rotM,(img_w,img_h))\n",
    "    img_warp = cv2.warpAffine(img_warp,transM,(img_w,img_h))\n",
    "    img_warp = cv2.warpAffine(img_warp,shearM,(img_w,img_h))\n",
    "\n",
    "    return img_warp.reshape(-1, *img_warp.shape)\n",
    "\n",
    "\n",
    "\n",
    "def augmentData(X_data, y_data, multiplier=2):\n",
    "\n",
    "    X_data_augs = [X_data]\n",
    "    y_data_augs = [y_data]\n",
    "    \n",
    "    vals, inverse, counts = np.unique(y_data, return_inverse=True, return_counts=True)\n",
    "    rows, cols            = np.where (inverse == vals[:, np.newaxis])\n",
    "    _   , inverse_rows    = np.unique(rows, return_index=True)\n",
    "    class_indices_list =  np.split(cols, inverse_rows[1:])\n",
    "    \n",
    "    class_labels, class_counts = np.unique(y_data, return_counts=True)\n",
    "    \n",
    "    n_target = np.int(multiplier*np.max(class_counts))\n",
    "    n_augs = [n_target - class_count for class_count in class_counts]\n",
    "    \n",
    "    print(\"Target num of samples for each class: {}\".format(n_target))\n",
    "    print(\"Total num of training samples: {}\\n\".format(n_target*len(class_labels)))\n",
    "    for class_label, n_aug, class_indices_data in zip(class_labels, n_augs, class_indices_list):    \n",
    "        \n",
    "        #print(\"Augmenting class: {:2} with {:4} samples\".format(class_label, n_aug))\n",
    "        for idx, class_idx in enumerate(np.random.choice(class_indices_data, size=n_aug)):\n",
    "            \n",
    "            X_data_augs.append(transform_image(X_data[class_idx]))\n",
    "            y_data_augs.append(y_data[class_idx])\n",
    "    \n",
    "    return np.vstack(X_data_augs), np.hstack(y_data_augs)\n",
    "\n",
    "\n",
    "# training dataset augmentation\n",
    "X_train_augs, y_train_augs                      = augmentData(X_train, y_train)\n",
    "X_train_std, X_val_std, y_train_std, y_val_std  = train_test_split(X_train_augs, y_train_augs, test_size=0.15)\n",
    "\n",
    "n_classes, n_classes_count_tr = np.unique(y_train, return_counts=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_image(img, angle_range = 20, trans_range = 15, shear_range = 10):\n",
    "    img_h, img_w, img_ch = img.shape\n",
    "    img_warp = np.copy(img)\n",
    "\n",
    "    #Generate random rotation matrix\n",
    "    rot = np.random.uniform(angle_range) - angle_range/2\n",
    "    rotM = cv2.getRotationMatrix2D((img_w/2,img_h/2),rot,1)\n",
    "\n",
    "    #Generate random tranlation matrix\n",
    "    tr_x, tr_y = trans_range*np.random.uniform(size=(2,1))-trans_range/2\n",
    "    transM = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "\n",
    "    #Generate random sheer matrix\n",
    "    pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "    pt1  = 5+shear_range*np.random.uniform()-shear_range/2\n",
    "    pt2  = 20+shear_range*np.random.uniform()-shear_range/2\n",
    "    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "    shearM = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "    #Apply transformation\n",
    "    img_warp = cv2.warpAffine(img_warp, rotM, (img_w, img_h))\n",
    "    img_warp = cv2.warpAffine(img_warp, transM, (img_w, img_h))\n",
    "    img_warp = cv2.warpAffine(img_warp, shearM, (img_w, img_h))\n",
    "    img_res = img_warp.reshape(-1, img_warp.shape)\n",
    "    \n",
    "    return img_res\n",
    "\n",
    "def test_imgtransform():\n",
    "    idx = np.random.randint(0, len(X_train))\n",
    "    image = X_train[idx].squeeze() #explicit array conversion\n",
    "\n",
    "    gs1 = gridspec.GridSpec(10, 2)\n",
    "    gs1.update(wspace=0.01, hspace=0.02) # set the spacing between axes. \n",
    "    plt.figure(figsize=(12,12))\n",
    "    for i in range(20):\n",
    "        ax1 = plt.subplot(gs1[i])\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "        ax1.set_aspect('equal')\n",
    "        img = transform_image(image,20,10,5)\n",
    "\n",
    "        plt.subplot(10,2,i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "\n",
    "    #plt.show()\n",
    "    return(plt)\n",
    "\n",
    "test_imgtransform().show()\n",
    " \n",
    "def augmentData(X_data, y_data, multiplier = 1.5):\n",
    "    \n",
    "    print('X data, y data',X_data.shape, y_data.shape)\n",
    "    \n",
    "    X_aug = [X_data]\n",
    "    y_aug = [y_data]\n",
    "    \n",
    "    class_labels, class_counts = np.unique(y_data, return_counts = True)\n",
    "    print(\"class label size\", class_labels.shape)\n",
    "    \n",
    "    # list of indices for each class\n",
    "    vals, inverse, counts = np.unique(y_data, return_inverse=True, return_counts=True)\n",
    "    rows, cols            = np.where (inverse == vals[:, np.newaxis])\n",
    "    _   , inverse_rows    = np.unique(rows, return_index=True)\n",
    "    class_indices_list = np.split(cols, inverse_rows[1:])\n",
    "    \n",
    "    \n",
    "    # list of number images to be augmented\n",
    "    n_target = np.int(multiplier*np.max(class_counts))\n",
    "    n_augs = [n_target - class_count for class_count in class_counts]\n",
    "    print(len(n_augs))\n",
    "    \n",
    "    for class_label, n_aug, class_indices in zip(class_labels, n_augs, class_indices_list):    \n",
    "        \n",
    "        #print(\"Augmenting class \",class_label,\" with \",n_aug,\" generated images\")\n",
    "        print(\"Augmenting class \",class_label,\" with \",n_aug,\" generated images\")\n",
    "        for idx, class_idx in enumerate(np.random.choice(class_indices, size=n_aug)):\n",
    "            \n",
    "            X_aug.append(transform_image(X_data[class_idx]))\n",
    "            y_aug.append(y_data[class_idx])\n",
    "            \n",
    "        print(len(X_aug))\n",
    "        \n",
    "    X_aug = np.vstack(X_aug)\n",
    "    y_aug = np.hstack(y_aug)\n",
    "    \n",
    "    return(X_aug,y_aug)\n",
    "\n",
    "X_data_aug, y_data_aug = augmentData(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:car]",
   "language": "python",
   "name": "conda-env-car-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
